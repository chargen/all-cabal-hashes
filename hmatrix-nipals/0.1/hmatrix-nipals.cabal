-- BEGIN Added by all-cabal-hashes-tool
x-package-hashes:
    MD5:824073bf9945b003012c9b774f3a5978
    SHA1:803ec4ca88322e081b0d347219e10259537d8018
    SHA256:20f688a44b18e5685da71cdbd0d187b0d4524c9d04d02b5e30234fac4287ee41
    SHA512:52e8abe09e9799fc488fcecbb2ec0b4053ed718bb52aeacd0c01b674589ed18a7cc77a5796429f81c3d49717483161be892cb595b624ecc1cd7337b9961eb48e
    Skein512_512:cead1b18271c93e8935d9626eb9f49bb16d399d81dec49788357184244782a8b70ed2be107434080534200da02d6e52ed3f7905d85816ecd5014f1bd85906a6f

x-package-locations:
    https://hackage.haskell.org/package/hmatrix-nipals-0.1/hmatrix-nipals-0.1.tar.gz
    https://s3.amazonaws.com/hackage.fpcomplete.com/package/hmatrix-nipals-0.1.tar.gz

x-package-size: 12566
-- END Added by all-cabal-hashes-tool

Name:                hmatrix-nipals
Version:             0.1
Synopsis:
  NIPALS method for Principal Components Analysis on large data-sets.

Description:
  NIPALS -- Nonlinear Iterative Partial Least Squares
  <http://en.wikipedia.org/wiki/NIPALS>, is a method for iteratively
  finding the left singular vectors of a large matrix. In other words
  it discovers the largest principal component
  <http://en.wikipedia.org/wiki/Principal_component> of a set of
  mean-centred samples, along with the score (the magnitude of the
  principal component) for each sample, and the residual of each
  sample that is orthogonal to the principal component. By repeating
  the procedure on the residuals, the second principal component is
  found, and so on.
  .
  The advantage of NIPALS over more traditional methods, like SVD, is
  that it is memory efficient, and can complete early if only a small
  number of principal components are needed. It is also simple to
  implement correctly. Additionally, because it doesn't pre-condition
  the sample matrix in any way, it can be implemented with only two
  sequential passes per iteration through the sample data, which is
  much more efficient than random accesses if the data-set is too
  large to fit in memory.
  .
  NIPALS is not generally recommended because sample matrices where
  the largest eigenvalues are close in magnitude will cause NIPALS to
  converge very slowly. In general, Lanczos methods
  <http://en.wikipedia.org/wiki/Lanczos_algorithm> or some other
  truncated singular value decomposition algorithm are preferred to
  NIPALS because of this convergence issue, but these methods often
  require the sample matrix to fit in memory, or store large
  conditioning matrices, which isn't always feasible. However, if you
  know of free and memory-efficient implementations of these more
  sophisticated algorithms, please contact the author with a pointer.

Homepage:            http://github.com/alanfalloon/hmatrix-nipals
License:             LGPL-2.1
License-file:        LICENSE
Author:              Alan Falloon
Maintainer:          alan.falloon@gmail.com
Copyright:           Copyright (c) 2011 Alan Falloon
Stability:           Experimental
Category:            Math
Build-type:          Simple
Cabal-version:       >=1.4

Flag test
  Description:       Build unit-tests
  Default:           False

Library
  Hs-source-dirs:    src
  Exposed-modules:
    Numeric.LinearAlgebra.NIPALS
  Build-depends:
    base >= 3 && < 5,
    hmatrix >= 0.11

Executable test
  Main-is:           tests.hs
  Hs-source-dirs:    src test
  if flag(test)
    Build-depends:
      QuickCheck >= 2.4,
      base >= 3 && < 5,
      hmatrix >= 0.11,
      test-framework >= 0.3,
      test-framework-quickcheck2 >= 0.2.9
  else
    Buildable:       False
