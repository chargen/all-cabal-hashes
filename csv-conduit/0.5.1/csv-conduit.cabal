-- BEGIN Added by all-cabal-hashes-tool
package-hashes:
    MD5:b5941c6158ac5f8e41b9cc5d913ebd8e
    SHA1:59eeaee35f7ead52bbf51818be27cf0c05f7efd4
    SHA256:4229862f7752f13fde259a2f51bcac83211bf06e2f974b2386b23197796affc9
    SHA512:d897941859f87e30894d041aa625fb528a5e0dfde31532dc65d03b1f4b9a95d8cd4fd318b20191988549834875c4dad7f9b09462fb639e087e665004664dbb03
    Skein512_512:a833b797e134d79367a2dc5eb6d2d49698511a3d7d462173287487cdc5f1a25c1b58e9dc7117ddf230a0c2b58febae6ea30cb26397226640c081590703061b0e

package-locations:
    https://hackage.haskell.org/package/csv-conduit-0.5.1/csv-conduit-0.5.1.tar.gz
    https://s3.amazonaws.com/hackage.fpcomplete.com/package/csv-conduit-0.5.1.tar.gz

package-size: 8248
-- END Added by all-cabal-hashes-tool

Name:                csv-conduit
Version:             0.5.1
Synopsis:            A flexible, fast, conduit-based CSV parser library for Haskell.
Homepage:            http://github.com/ozataman/csv-conduit
License:             BSD3
License-file:        LICENSE
Author:              Ozgun Ataman
Maintainer:          Ozgun Ataman <ozataman@gmail.com>
Category:            Data, Conduit, CSV, Text
Build-type:          Simple
Cabal-version:       >= 1.9.2
Tested-with:         GHC == 7.6.1
Description:
  CSV files are the de-facto standard in many situations involving data transfer,
  particularly when dealing with enterprise application or disparate database
  systems.

  .

  While there are a number of CSV libraries in Haskell, at the time of this
  project's start in 2010, there wasn't one that provided all of the following:

  .

  * Full flexibility in quote characters, separators, input/output
  .
  * Constant space operation
  .
  * Robust parsing, correctness and error resiliency
  .
  * Convenient interface that supports a variety of use cases
  .
  * Fast operation
  .

  This library is an attempt to close these gaps. Please note that
  this library started its life based on the enumerator package and
  has recently been ported to work with conduits instead. In the
  process, it has been greatly simplified thanks to the modular nature
  of the conduits library.

  .

  Following the port to conduits, the library has also gained the
  ability to parameterize on the stream type and work both with
  ByteString and Text.

  .

  For more documentation and examples, check out the README at:
  .

  <http://github.com/ozataman/csv-conduit>
  .


extra-source-files:
  README.markdown
  test/test.csv
  test/Test.hs
  test/Bench.hs

library
  exposed-modules:
      Data.CSV.Conduit
      Data.CSV.Conduit.Parser.ByteString
      Data.CSV.Conduit.Parser.Text
  other-modules:
      Data.CSV.Conduit.Types
  ghc-options: -Wall
  hs-source-dirs: src
  build-depends:
      attoparsec >= 0.10
    , attoparsec-conduit >= 0.5.0.2
    , base >= 4 && < 5
    , bytestring
    , conduit >= 1.0 && < 2.0
    , containers >= 0.3
    , monad-control
    , text
    , data-default
  ghc-options: -funbox-strict-fields
  ghc-prof-options: -fprof-auto

test-suite test
  type: exitcode-stdio-1.0
  main-is: Test.hs
  ghc-options: -Wall
  hs-source-dirs: test
  build-depends:
      base >= 4 && < 5
    , bytestring
    , containers >= 0.3
    , csv-conduit
    , directory
    , HUnit >= 1.2
    , test-framework
    , test-framework-hunit
    , text

flag bench
  default: False
  manual: True

executable bench
  main-is: Bench.hs
  if flag(bench)
    buildable: True
  else
    buildable: False
  ghc-options: -Wall
  hs-source-dirs: test
  build-depends:
      base >= 4 && < 5
    , bytestring
    , containers >= 0.3
    , csv-conduit
    , directory
    , text
  ghc-options: -rtsopts
  ghc-prof-options: -rtsopts -caf-all -auto-all
